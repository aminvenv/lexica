{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2193326d-fb5b-471e-9f0d-6c445d923c52",
   "metadata": {},
   "source": [
    "define the necessary objects and functions for indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b03b5f35-c9e0-40ce-be90-d37729e5feb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import ast\n",
    "import json\n",
    "import time\n",
    "import json\n",
    "import pandas\n",
    "\n",
    "import elasticsearch\n",
    "from elasticsearch import helpers\n",
    "\n",
    "ELASTI_HOST = '127.0.0.1' \n",
    "ELASTIC_PORT = 'port number' \n",
    "\n",
    "class ElasticSearch:\n",
    "    def __init__(self):\n",
    "        config = {\n",
    "            ELASTI_HOST: ELASTIC_PORT\n",
    "        }\n",
    "        self.es = elasticsearch.Elasticsearch([config, ], timeout=300)\n",
    "        self.last_scroll_id = None\n",
    "\n",
    "    def create_index(self, name, mapping, replace=False):\n",
    "        if replace:\n",
    "            self.delete_index(name)\n",
    "        print(\"creating index, name: \", name)\n",
    "        self.es.indices.create(index=name, body=mapping)\n",
    "        print(\"index created successfully, index name: \" + name)\n",
    "\n",
    "    def delete_index(self, name):\n",
    "        print(\"deleting index, name: \", name)\n",
    "        self.es.indices.delete(index=name, ignore=[400, 404])\n",
    "        print(\"index deleted successfully, index name: \" + name)\n",
    "\n",
    "    def index(self, documents, index_name, is_bulk=False):\n",
    "        if is_bulk:\n",
    "            try:\n",
    "                response = helpers.bulk(self.es, documents)\n",
    "                print(\"\\nRESPONSE:\", response)\n",
    "            except Exception as e:\n",
    "                print(\"\\nERROR:\", e)\n",
    "\n",
    "    def search(self, index, body):\n",
    "        try:\n",
    "            return self.es.search(index=index, body=body)\n",
    "        except Exception as e:\n",
    "            print(\"\\nERROR:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2db52e-5b3e-4148-b21d-43dcca2c211e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenized_docs_scidocs(index_name, docs_csv_path, application_in_training, type_):\n",
    "    docs = []\n",
    "    docs_df = pd.read_csv(docs_csv_path, sep='\\t', names=['doc_id', 'doc_text', 'bertext'])\n",
    "    for row in docs_df.itertuples():\n",
    "        if len(docs) % 10000 == 0:\n",
    "            print(\"{} docs parsed\".format(len(docs)))\n",
    "        id_ = str(row.doc_id)\n",
    "        # contents = str(row.bertext) # for indexing the tokenized text\n",
    "        contents = str(row.doc_text) # for indexing the normal text\n",
    "\n",
    "        doc = {\n",
    "            \"_index\": index_name,\n",
    "            \"_id\": id_,\n",
    "            \"application_in_training\": application_in_training,\n",
    "            \"content\": contents,\n",
    "            \"original_id\": id_\n",
    "        }\n",
    "        docs.append(doc)\n",
    "    return docs\n",
    "\n",
    "def get_mapping(type_):\n",
    "    if type == \"para\":\n",
    "        pass\n",
    "    else:\n",
    "        return json.loads(open(\"./mapping.json\").read())\n",
    "\n",
    "def delete_index(index_name):\n",
    "    es = ElasticSearch()\n",
    "    es.delete_index(index_name)\n",
    "\n",
    "\n",
    "def indexing_w_passaging(type_,\n",
    "             index_name,\n",
    "             file_path,\n",
    "             application_in_training,\n",
    "             replace_index,\n",
    "             mapping,\n",
    "             passaging_params={'text_attr':\"text\",\n",
    "                               'length':0,\n",
    "                               'stride':0,\n",
    "                               'prepend_title':False}):\n",
    "    pass\n",
    "            \n",
    "\n",
    "def indexing_wo_passaging(type_,\n",
    "                          index_name,\n",
    "                          file_path,\n",
    "                          application_in_training,\n",
    "                          replace_index,\n",
    "                          mapping,\n",
    "                         passaging_params=None):\n",
    "    print(\"indexer run.. type: {}, index_name: {}, file_path: {}\",\n",
    "          type_, index_name, file_path)\n",
    "    docs = get_tokenized_docs_scidocs(index_name, file_path, application_in_training, type_)\n",
    "    es = ElasticSearch()\n",
    "\n",
    "    print(\"creating index mapping...\")\n",
    "    es.create_index(index_name, mapping, replace=replace_index)\n",
    "    print(\"index mapping created !\")\n",
    "\n",
    "    print(\"indexing documents started...: \")\n",
    "    es.index(index_name=index_name, documents=docs, is_bulk=True)\n",
    "    print(\"all docs indexed :)\")\n",
    "    \n",
    "def indexing(passaging_mode, **kwargs):\n",
    "    \n",
    "    if passaging_mode:\n",
    "        pass\n",
    "    else:\n",
    "        indexing_wo_passaging(kwargs['type_'],\n",
    "                              kwargs['index_name'],\n",
    "                              kwargs['file_path'],\n",
    "                              kwargs['application_in_training'],\n",
    "                              kwargs['replace_index'],\n",
    "                              kwargs['mapping'],\n",
    "                              kwargs['passaging_params'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579257a4-8e0b-41b9-a6dd-6e8c230c5aba",
   "metadata": {},
   "source": [
    "set parameters for indexing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f38d19d3-d98f-4ac5-9186-81cf1e35b858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### for bm25\n",
    "# index_setting = {\n",
    "# #         \"analysis\": {\n",
    "# #       \"analyzer\": {\n",
    "# #         \"my_analyzer\": {\n",
    "# #           \"tokenizer\": \"whitespace\",\n",
    "# #           \"filter\": [\n",
    "# #             \"lowercase\",\n",
    "# #             \"porter_stem\"\n",
    "# #           ]\n",
    "# #         }\n",
    "# #       }\n",
    "# #     },\n",
    "#     \"index\": {\n",
    "#         \"similarity\": {\n",
    "#             \"default\": {\n",
    "#                 \"type\": \"BM25\",\n",
    "#                 \"b\": bm25_b,\n",
    "#                 \"k1\": bm25_k1\n",
    "#             }\n",
    "#         },\n",
    "#         'number_of_shards': 1,\n",
    "#         'number_of_replicas': 1\n",
    "#     }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6134e58d-3de7-4fc8-9acc-3376982b1a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for lm\n",
    "index_setting = {\n",
    "    \"index\": {\n",
    "        \"similarity\": {\n",
    "              \"default\" : {\n",
    "                \"type\" : \"LMJelinekMercer\",\n",
    "              }\n",
    "        },\n",
    "        'number_of_shards': 1,\n",
    "        'number_of_replicas': 1\n",
    "    }}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d1bc71-f3d7-4653-bf57-b61af1926a5e",
   "metadata": {},
   "source": [
    "indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d884181-b3cd-454d-8428-17ab22d94d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "index_name = 'name/of/the/index'\n",
    "type_ = \"whole\" # use it as default\n",
    "\n",
    "file_path = 'path/to/tokenized/docs/with/bert/or/scibert'\n",
    "\n",
    "passaging_mode = False\n",
    "\n",
    "application_in_training = \"corpus\"\n",
    "replace_index = True\n",
    "mapping = get_mapping(type_)\n",
    "\n",
    "\n",
    "mapping['settings'].update(index_setting)\n",
    "\n",
    "\n",
    "indexing(passaging_mode=passaging_mode,\n",
    "         type_=type_,\n",
    "         index_name=index_name,\n",
    "         file_path=file_path,\n",
    "         application_in_training=application_in_training,\n",
    "         replace_index=replace_index,\n",
    "         mapping=mapping,\n",
    "         passaging_params={'text_attr':\"text\",\n",
    "                               'length':0,\n",
    "                               'stride':0,\n",
    "                               'prepend_title':False}, )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31952264-f4bb-4579-b0e7-c0a3b5a0fc1f",
   "metadata": {},
   "source": [
    "connect to the elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43bbe465-86d6-47b7-9c63-4d861b7a2268",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "class ES_conn():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.client = None\n",
    "        self.start_connection()\n",
    "\n",
    "    def start_connection(self):\n",
    "        self.client = Elasticsearch(host='localhost',port='select/port/number', timeout=30)\n",
    "\n",
    "\n",
    "elastic_server = ES_conn()\n",
    "elastic_server.start_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a43947-5e31-478f-91da-aa6600d24c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_server.client.indices.refresh()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d58f59-abc2-405f-8774-e56a0b9cdd85",
   "metadata": {},
   "source": [
    "Read the test qrels with query text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59339e5d-789a-4e49-bac2-43cc5c1ba8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "task_name = 'coview' # coread # cocite # cite  # coview\n",
    "feb_qrel_w_tkned_qtext = pd.read_csv('path/to/test_qrel with scibert tokenized query text for task_name',\n",
    "                                     sep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab2596d-f9c6-4b45-9e82-77ce8619fd77",
   "metadata": {},
   "source": [
    "Ranking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c78207-7543-4366-a3ec-70cb28b0f8f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import operator\n",
    "import secrets\n",
    "import random\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "from elasticsearch import Elasticsearch\n",
    "from tqdm import tqdm\n",
    "import json \n",
    "\n",
    "\n",
    "f = open('../data/docid2index.json')\n",
    "docid2index = json.load(f)\n",
    "f.close()\n",
    "\n",
    "\n",
    "\n",
    "def res_wrapper(query_id: str, q: int, doc_id: str, rank: int, score: float, run_id: str):\n",
    "    return [query_id, q, doc_id, rank, score, run_id]\n",
    "\n",
    "\n",
    "def es_search(q_id, query_text, docno_, index, top_k):\n",
    "    bool_query = {\n",
    "                    \"size\": topk,\n",
    "                    \"query\": {\n",
    "                        \"bool\": {\n",
    "                            \"must\": [\n",
    "                                {\"term\": {\"original_id\": docno_}}\n",
    "                            ],\n",
    "                            \"should\": [\n",
    "                                {\"match\": {\"content\": query_text}}\n",
    "                            ]\n",
    "                            ,\"minimum_should_match\": 0,\n",
    "                            \"boost\": 1.0\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "\n",
    "    query_template = bool_query\n",
    "    res = elastic_server.client.search(index=index, body=query_template)\n",
    "    return res\n",
    "\n",
    "\n",
    "def elastic_batchretrieve(topics_df, index_name, topk):\n",
    "    hits = []\n",
    "    \n",
    "    for row in tqdm(topics_df.itertuples()):\n",
    "        try:\n",
    "\n",
    "            res = es_search(row.qid, row.query_text, row.docno, index_name,  topk)\n",
    "            for rank, hit in enumerate(res['hits']['hits'], 1):\n",
    "                hits.append(res_wrapper(rank=rank, doc_id=hit['_id'], q=0, score=hit['_score'],\n",
    "                                            run_id='scidocs', query_id=row.qid))\n",
    "        except:\n",
    "            print(row.qid, row.query_text)\n",
    "\n",
    "    return hits\n",
    "\n",
    "\n",
    "index_name = 'name/of/the/index'\n",
    "hits = elastic_batchretrieve(feb_qrel_w_tkned_qtext, index_name, 1)\n",
    "res_df = pd.DataFrame(hits, columns=['qid', 'query', 'docno', 'rank', 'score', 'run_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e826712-e9cc-4263-8065-1b4bc7968eac",
   "metadata": {},
   "source": [
    "save the run file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9cb2397-80b8-4ece-a43c-b823b641a999",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.to_csv('path/to/run/file/', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40e5ddb-93fb-4fc4-a259-b11719a62d55",
   "metadata": {},
   "source": [
    "evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2d87530-8a91-4255-b375-a88ea7f4f6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.to_csv('./temp.run', header=False, index=False, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed70651-e8fc-4cd4-ac4a-fe75219ecf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_utils import qrel_metrics\n",
    "import numpy as np\n",
    "\n",
    "qrel_file = '../data/'+task_name+'_data/test.qrel'\n",
    "\n",
    "run_file = './temp.run'\n",
    "\n",
    "print(task_name)\n",
    "res_dict = qrel_metrics(qrel_file, run_file, metrics=('ndcg', 'map'))\n",
    "for item in res_dict:\n",
    "    print(item, np.around(res_dict[item], 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
